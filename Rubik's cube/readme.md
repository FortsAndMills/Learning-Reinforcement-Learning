## Текущая версия
* Double DQN
** с учётом детерминированности среды превращается в из Q-learning-а в V-learning
* хубер-лосс вместо обычного квадратичного (дополнительная стабилизация лосса)
* кастомная стратегия exploration-а (вычитаем из Q(s, a) максимальное по a значение, прибавляем единицу. Убираем все д
